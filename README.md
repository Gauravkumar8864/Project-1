# Image Generation using Stable Diffusion and ComfyUI ğŸ¨ğŸ§ 

This project explores **AI-based image generation** using **Stable Diffusion**, a powerful latent diffusion model, with the help of **ComfyUI** â€” a modular, node-based GUI that provides intuitive workflows for generating high-quality images from text prompts. Additionally, a **Python GUI built with Tkinter** offers a simplified interface for local use.

---

## ğŸ“Œ Project Objective

To build a customizable and easy-to-use platform for generating AI-based images from natural language descriptions, while understanding the core concepts of Stable Diffusion, prompt engineering, and diffusion-based generative models.

---

## ğŸ”§ Features

- ğŸ”¤ **Text-to-Image generation** via Stable Diffusion
- ğŸ–¼ï¸ **ComfyUI Integration** for modular and visual workflows
- ğŸ–¥ï¸ **Custom GUI using Tkinter** to input prompts and generate images locally
- ğŸ§ª Support for **prompt engineering and customization**
- âš™ï¸ Local image generation without relying on Google Colab or web platforms

---

## ğŸ“ Project Structure

```bash
Project-1/
â”‚
â”œâ”€â”€ ComfyUI/                 # ComfyUI setup directory (linked or downloaded externally)
â”œâ”€â”€ gui/                     # GUI folder for the custom Tkinter interface
â”‚   â””â”€â”€ main.py              # Python file to launch the prompt-based interface
â”œâ”€â”€ outputs/                 # Directory to store generated images
â”œâ”€â”€ README.md                # This file
â””â”€â”€ requirements.txt         # Python dependencies
